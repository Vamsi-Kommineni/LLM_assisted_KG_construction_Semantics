 The context does not provide information on the specific measures taken to ensure the
generalizability of the deep learning model. However, it does mention that the models were trained
using Stochastic Gradient Descent (SGD) as the optimizer and that other hyperparameters like batch
size, learning rate, and number of epochs were obtained using the grid search. Additionally, the
models were implemented using Keras. The resulting hyperparameters for each model are shown in Table
II. The models were evaluated based on their performance on a test set, as shown in Table III and
Figures 6 and 7. The context also mentions that the data is highly unbalanced, and therefore, using
SMOTE or similar data balancing techniques may help improve the results further.