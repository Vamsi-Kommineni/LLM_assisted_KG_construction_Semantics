The deep learning pipeline uses image data for training and classification. %Context layer reduces the vector of image features to the desired dimension- ality of length two (foreground and background). The softmax layer normalises this vector into probabilities that sum to one across all classes. DeepMeerkat is designed to be conservative, with a high F I G U R E 2 The front screen of the DeepMeerkat GUI. A user can select a file or directory of videos to screen using a pre- trained model. The path to the model is set under “Advanced settings” threshold for retaining frames (acceptance value = 0. 1). This means that the model must be more than 90% confident that a frame does not contain a foreground object to assign a background label. This prioritises minimising false negatives at the potential expense of in- majority of hummingbird visitation events (Weinstein, 2015). For the purposes of this article, I assumed that all events are captured by For training the fine- tuned neural network, I collected images for each class and trained with a batch size of 100 for 20,000 steps. To reduce training time, the feature vectors for the frozen layers were extracted in parallel using Google Cloud DataFlow. These features were then the basis for retraining the new fine- tuned layers. To fit the specifications of the pre- trained frozen layers, the bounding boxes from motion detection were resized into three channel arrays with height and width of 299 pixels. Following Zhang, He, Cao, and Cao (2016), aspect ratios of bounding boxes were not maintained when passing boxes to the neural network. Model performance was measured using true positive rate, true negative rate, and precision. A DeepMeerkat GUI (Figure 2, Figures S1 and S2) is available for download for Mac and Windows with the pre- trained humming- 3 | R E S U L T S Deng, J. , Dong, W. , Socher, R. , Li, L-J. , Li, K. , & Fei-Fei, L. (2009). ImageNet: A large-scale hierarchical image database. 2009 IEEE Conference on Computer Vision and Pattern Recognition, (June), (pp. 248–255). https://doi. org/10. 1109/cvprw. 2009. 5206848 Elias, A. R. , Golubovic, N. , Krintz, C. , & Wolski, R. (2017). Where’s the bear? – Automating wildlife image processing using IoT and edge WEINSTEIN 2041210x, 2018, 6, Downloaded from https://besjournals. onlinelibrary. wiley. com/doi/10. 1111/2041-210X. 13011 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary. com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License | 1441 Methods in Ecology and Evolu(cid:13)on Wilf, P. , Zhang, S. , Chikkerur, S. , Little, S. A. , Wing, S. L. , & Serre, T. (2016). Computer vision cracks the leaf code. Proceedings of the National Academy of Sciences of the United States of America, 113, 201524473. Zhang, Z. , He, Z. , Cao, G. , & Cao, W. Animal detection from highly cluttered natural scenes using spatiotemporal object region propos- als and patch verification. IEEE Transactions on Multimedia, 18, 2079– 2092. 1109/TMM. 2016. 2594138 How to cite this article: Weinstein BG. Scene- specific convolutional neural networks for video- based biodiversity detection. Methods Ecol Evol. 2018;9:1435–1441. 13011 S U P P O R T I N G I N FO R M AT I O N Additional supporting information may be found online in the Supporting Information section at the end of the article. Helpful 