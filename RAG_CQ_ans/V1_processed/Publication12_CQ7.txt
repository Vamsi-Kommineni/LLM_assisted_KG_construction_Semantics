The data was split into a training dataset with 85% of images (111,244/130,858) and a validation dataset with 15% (19,614/130,858) using a Python script Making_dataset. py in Waveman. The images were manually assigned into four categories: strong, weak, no call, and background noise. The weak and no call categories contained 10-100 images from each audio-file of different species. The images with a size of 256*256 pixels were converted to 64*64 pixels to save training time and reduce high memory graphics use. To balance the image number for all the species, an upper limit was provided for when a species had too much data. A method was also developed to increase the number of images for the rare species, in which signals were rescaled exponentially, and the window was shifted slightly either side of the call to change background noise. Both these measures ensure rare species with small image numbers will not be under-represented and under-classified relative to common species. 