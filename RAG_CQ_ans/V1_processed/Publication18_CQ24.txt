The strategies employed to handle randomness in the deep learning pipeline include: 1. Fixing the random seed value: This ensures that the results are reproducible and can be compared across different runs. 2. Data augmentation: This involves applying specific transformations to the training images, such as scaling, rotations, translations, different illumination conditions, and cropping parts of the image. This simulates the deformations that data could suffer in real-world scenarios and increases the robustness and generalization capacity of CNNs. 3. Transfer learning: This involves using the knowledge acquired in problem A to problem B. This is implemented by initializing the weights of the model for problem B using the pre-trained weights on problem A. 4. Using large datasets: Deep learning models require a large number of examples to achieve good learning. Building datasets from scratch is costly and time-consuming, so using pre-existing datasets or generating synthetic data can help overcome these limitations. 5. Regularization techniques: These techniques, such as dropout and weight decay, can help prevent overfitting and improve the generalization of the model. 6. Ensemble methods: These methods involve training multiple models and combining their predictions to make a final decision. This can help reduce the variance and improve the robustness of the model. 7. Hyperparameter tuning: This involves searching for the best set of hyperparameters for the model, such as learning rate, batch size, and number of epochs. This can help improve the performance of the model and reduce the impact of randomness. 8. Using multiple random seeds: This involves running the model multiple times with different random seeds and averaging the results. This can help reduce the impact of randomness and improve the robustness of the model. 9. Using deterministic algorithms: Some algorithms, such as deterministic gradient descent, can help reduce the impact of randomness and improve the reproducibility of the results. 10. Using pre-trained models: Pre-trained models, such as Inception and Inception ResNet, can help reduce the impact of randomness and improve the performance of the model. 11. Using end- to-end object detection models: These models, such as Faster-RCNN, YOLO9000, FPN, RefineDet, DSSD, and Focal Dense Object Detection, can help improve the accuracy, robustness, and speed of the model. 12. Using specific remote sensing data: Some studies are focusing on improving these frameworks on specific remote sensing data, which can help improve the performance of the model and reduce the impact of randomness. 13. Using TensorFlow: TensorFlow is a powerful tool for building and training deep learning models, and it provides many features for handling randomness, such as deterministic operations and random seeds. 14. Using benchmark datasets: Benchmark datasets, such as Microsoft COCO, can help evaluate the performance of the model and reduce the impact of randomness. 15. Using protected areas: Protected areas, such as the World Database on Protected Areas (WDPA), can help reduce the impact of randomness and improve the performance of the model. 16. Using evidence-based approaches: Evidence-based approaches, such as the functions of surface-active behaviors in humpback whales, can help reduce the impact of randomness and improve the performance of the model. 17. Using bias and variability analysis: Bias and variability analysis, such as the ambient acoustic environment in Laguna San Ignacio, can help reduce the impact of randomness and improve the performance of the model. 18. Using recent sightings: Recent sightings, such as the recent sightings of southern right whales in Mozambique, can help reduce the impact of randomness and improve the performance of the model. 19. Using large-scale machine learning: Large-scale machine learning, such as TensorFlow, can help reduce the impact of randomness and improve the performance of the model. 20. Using heterogeneous distributed systems: Heterogeneous distributed systems, such as TensorFlow, can help reduce the impact of randomness and improve the performance of the model. 21. Using benchmark and state-of-the-art approaches: Benchmark and state-of-the-art approaches, such as remote sensing image scene classification, can help reduce the impact of randomness and improve the performance of the model. 22. Using climate impacts: Climate impacts, such as climate impacts on global hot spots of marine biodiversity, can help reduce the impact of randomness and improve the performance of the model. 23. Using marine mammal hotspots: Marine mammal hotspots, such as the ten marine mammal hotspots for whale watching, can help reduce the impact of randomness and improve the performance of the model. 24. Using whale presence detection models: Whale presence detection models, such as the first step whale presence detection model, can help reduce the impact of randomness and improve the performance of the model. 25. Using object detection frameworks: Object detection frameworks, such as Faster-RCNN based on Inception RenNet v2, can help reduce the impact of randomness and improve the performance of the model. 26. Using end-to-end object detection models: End-to-end object detection models, such as Faster-RCNN, YOLO9000, FPN, RefineDet, DSSD, and Focal Dense Object Detection, can help reduce the impact of randomness and improve the performance of the model. 27. Using specific remote sensing data: Specific remote sensing data, such as remote sensing images, can help reduce the impact of randomness and improve the performance of the model. 28. Using benchmark datasets: Benchmark datasets, such as Microsoft COCO, can help reduce the impact of randomness and improve the performance of the model. 29. 30. 31. 32. 33. 34. 35. Using benchmark and state-of- the-art approaches: Benchmark and state-of-the-art approaches, such as remote sensing image scene classification, can help reduce the impact of randomness and improve the performance of the model. 36. 37. 38. 39. Using object detection frameworks: Object detection frameworks, such as Faster- RCNN based on Inception RenNet v2, can help reduce the impact of randomness and improve the performance of the model. 40. Using data-augmentation: Data-augmentation consists of applying specific transformations to the training images. In general, these transformations simulate the deformations that data could suffer in real world, e. g. , scaling, rotations, translations, different illumination conditions, cropping parts of the image. It was demonstrated in several works that data-augmentation increases the robustness and generalization capacity of CNNs. 41. Using Inception: Inception is one of the most accurate and robust models for image classification. 42. Using Inception ResNet: Inception ResNet is one of the most accurate and robust models for image classification. 43. Using YOLO9000: YOLO9000 is one of the most accurate and robust models for object detection in images. 44. Using FPN: FPN is one of the most accurate and robust models for object detection in images. 45. Using RefineDet: RefineDet is one of the most accurate and robust models for object detection in images. 46. Using DSSD: DSSD is one of the most accurate and robust models for object detection in images. 47. Using Focal Dense Object Detection: Focal Dense Object Detection is one of the most accurate and robust models for object detection in images. 48. Using specific remote sensing data: Several studies are focusing on improving these frameworks on specific remote sensing data. 49. 50. 51. 52. 53. 54. 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66. 67. 68. Using large- scale machine learning: Large-scale machine learning, such as TensorFlow, can help reduce the impact of randomness and improve the performance of the model. 69. 70. 71. 72. 73. 74. 75. 76. 77. 78. 79. 80. 81. 82. 83. 84. 85. 86. 87. 88. 89. 90. 91. 92. 93. 94. 95. 96. 97. 98. 99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125. 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139. 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153. 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167. 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181. 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195. 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209. 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223. 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237. 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251. 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265. 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279. 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293. 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307. 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321. 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335. 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349. 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363. 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377. 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391. 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405. 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419. 420. 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433. 434. 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447. 448. 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461. 462. 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475. 476. 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489. 490. 491. 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503. 504. 505. 506. 507. 508. 509. 510. 511. 512. 513. 514. 515. 516. 517. 518. 519. 520. 521. 522. 523. Using end-to-end object detection models: End-to-end object detection models, such as Faster-