The process followed to deploy the trained deep learning model is not explicitly mentioned in the provided context. However, it is common practice to serialize the trained model and save it to a file, which can then be loaded and used for inference on a platform of choice. The platform selection would depend on the specific requirements of the application, such as computational resources, latency, and scalability. 