 %INSTRUCTIONS: Your task is to do Named Entity Recognition. You extract named entities from the provided competency question answers. 
        Use provided concepts to understand which named entities to extract from competency answers. 
        Concepts: Method, RawData, DataFormat, DataAnnotationTechnique, DataAugmentationTechnique, Dataset, PreprocessingStep, DataSplitCriteria, CodeRepository, DataRepository, CodeRepositoryLink, DataRepositoryLink, DeepLearningModel, Hyperparameter, HyperparameterOptimization, OptimizationTechnique, TrainingCompletionCriteria, RegularizationMethod, ModelPerformanceMonitoringStrategy, Framework, HardwareResource, PostprocessingStep, PerformanceMetric, GeneralizabilityMeasure, RandomnessStrategy, ModelPurpose, DataBiasTechnique, ModelDeploymentProcess, DeploymentPlatform.         
        Example: DeepLearningModel(CNN, RNN, Transformer), Framework(TensorFlow, PyTorch), PerformanceMetric(Accuracy, mean IoU)
        Below are the competency questions and answers: 
CQ: What data formats are used in the deep learning pipeline (e.g, image, audio, video, csv)?
Answer: The deep learning pipeline uses RGB data, which is a type of image data. It also uses LIDAR data, which is a type of point cloud data.

CQ: What are the data augmentation techniques applied in the deep learning pipeline (e.g, Fliping, Roating, Scaling)?
Answer: The context does not provide information on the specific data augmentation techniques applied in the deep learning pipeline. Therefore, I don't know the answer.

CQ: What are the datasets used in the deep learning pipeline (e.g, MNIST, CIFAR, ImageNet)?
Answer: The datasets used in the deep learning pipeline are not explicitly mentioned in the provided context. However, the context does mention that the pipeline uses RGB data and LIDAR data. It also mentions that the pipeline is used for detecting tree crowns. Therefore, it can be inferred that the datasets used in the pipeline are likely related to remote sensing and tree detection.

CQ: What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?
Answer: The context does not provide information on the specific preprocessing steps involved before training a deep learning model. However, common preprocessing steps for deep learning models include normalization, scaling, and cleaning. Normalization involves scaling the input data to a specific range, such as between 0 and 1. Scaling involves adjusting the input data to have a mean of 0 and a standard deviation of 1. Cleaning involves removing any irrelevant or incorrect data from the input dataset.

CQ: What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?
Answer: The code for this project is available on GitHub (<https://github. com/weecology/DeepLidar>) and archived on Zenodo [18].

CQ: What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?
Answer: The pipeline uses a self-supervised red, green, blue (RGB) deep learning model.

CQ: What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?
Answer: The context does not provide information on the hyperparameters used in the deep learning model, such as the learning rate or optimizer.

CQ: What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?
Answer: The provided context does not mention any specific optimization techniques applied in the deep learning pipeline, such as SGD or Adam.

CQ: What are the regularization methods used to prevent overfitting  in the deep learning pipeline (e.g., dropout, L2 regularization)?
Answer: The provided context does not mention any specific regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention that self-supervision, which only relies on unlabeled data, can be combined with labeled data in a semi-supervised framework, which may improve deep learning on limited training data by providing neural networks the opportunity to learn generalized features on a wider array of training examples, followed by retraining on a smaller number of high quality annotations. This approach could potentially help prevent overfitting, but the context does not provide specific details on the regularization methods used.

CQ: Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?
Answer: The context does not provide information on the specific frameworks used to build the deep learning model.

CQ: Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?
Answer: The context does not provide information on the specific hardware resources used for training the deep learning model.

CQ: What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?
Answer: The evaluation metrics used for the deep learning model are stem recall, precision, and recall for crown overlap. Stem recall was calculated using field-collected tree stem locations, while precision and recall for crown overlap were calculated on hand-annotated bounding boxes around each tree crown with a minimum predicted probability threshold of 0. 5.

CQ: What is the purpose of the deep learning model (e.g., classification, segmentation, detection)?
Answer: The purpose of the deep learning model is to perform tree delineation in new RGB imagery without the need for co-registered LIDAR data. This provides the potential for expanding the use of deep learning in remote sensing applications with limited labeled data.

Provide your answer as follows:
        Named Entities: For each provided Concept(Corresponding Named Entity,..), ...