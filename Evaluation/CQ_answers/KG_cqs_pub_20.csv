CQ_no,CQ,CQ_ans,Human_Evaluation
2,"What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?","The deep learning pipeline uses image data formats. Specifically, it uses thumbnails of whole fish, part of fish species, and environment. ",TRUE
5,"What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? ","The deep learning pipeline used four different datasets to assess the influence of the dataset building on classification results. These datasets are T1, T2, T3, and T4. T1 contained raw fish thumbnails and their respective mirror images. T2 contained whole fish and part of fish thumbnails. T3 contained whole fish, environment, and part of fish thumbnails. T4 contained whole fish, environment, and part of species thumbnails. The first training dataset T1 contained raw fish thumbnails (T0) and their respective mirror images. More precisely, they doubled the number of thumbnails per fish individual by flipping each thumbnail with respect to the vertical axis. This annotation procedure yielded a training dataset (T0) with 44,625 annotated fish thumbnails belonging to 20 species. The 20 species present in the training dataset represent the most common species appearing in the videos and belong to 12 families among the most diverse and abundant on coral reefs worldwide. ",TRUE
6,"What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?","The context does not provide explicit information about preprocessing steps before training a deep learning model. However, it mentions that the raw training dataset of 20 fish species was used to build 4 different datasets to assess the influence of the dataset building on classification results. This involved doubling the number of thumbnails per fish individual by flipping each thumbnail with respect to the vertical axis. This procedure homogenizes the proportion of left- oriented and right-oriented individuals in the database. Additionally, the context mentions that the training lasted 8 days on a computer with 64GB of RAM, an i7 3. 50GHz CPU, and a Titan X GPU card for 900,000 images. However, it does not provide specific details about preprocessing steps such as normalization, scaling, or cleaning. ",TRUE
4,"What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?",The data augmentation technique applied in the deep learning pipeline is flipping each thumbnail with respect to the vertical axis. This procedure homogenizes the proportion of left-oriented and right-oriented individuals in the database and is hypothesized to improve the average identification rate since fish individuals are seen in all positions.,TRUE
12,"What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?",The type of deep learning model used in the pipeline is a Convolutional Neural Network (CNN).,TRUE
15,"What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?",The deep learning pipeline uses a learning rate of 10 with a learning decay of 0. 95 and an Adam Solver type as learning parameters. These are classic hyper-parameters for a fast convergence of the network without over-fitting.,TRUE
13,"What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?","The hyperparameters used in the deep learning model are a learning rate of 10, a learning decay with a Gamma of 0. 95, a dropout of 50%, and an Adam Solver type as learning parameters. The weight initialization is a random Gaussian initialization. ",TRUE
22,"What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?","The performance of the deep learning model is evaluated using the mean identification success rate, correct identification rate, confusion between fish species, and success rate. The mean identification success rate is close to 87%, and the success rate ranges from 85. 2 to 100% with only 3 species being correctly identified in < 90% of cases and 9 species being correctly identified in > 95% of cases, including 3 with a correct identification rate > 99%. Confusions between 2 fish species were lower than 4%, and applying decision rule r1 decreased this error rate to < 4%. The best model had a lower performance than humans but both were higher than 97%. The mean time needed to identify a fish by humans was 5 s, with the fastest answer given in 2 s and the longest in 9 s. On average, each classification by the final model took 0. 06 s with hardware detailed above. ",TRUE
17,"What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?",The regularization methods used to prevent overfitting in the deep learning pipeline are dropout and learning decay with a Gamma of 0. 95. The dropout rate used is 50%.,TRUE
19,"Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?",The deep learning model is built using Caﬀe framework.,TRUE
20,"Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?","The deep learning model was trained on a computer with 64GB of RAM, an i7 3. 50GHz CPU, and a Titan X GPU card. ",TRUE
8,"Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?","The code repository of the deep learning pipeline is not explicitly mentioned in the provided context. Therefore, I cannot provide the exact location of the code repository. However, it is mentioned that the code was run on Caﬀe, which is a deep learning framework. It is possible that the code repository is available on the Caﬀe website or on a related platform. ",TRUE
25,"What is the purpose of the deep learning model (e.g., classification, segmentation, detection)?","The purpose of the deep learning model is to classify objects from images, specifically to identify fish species. ",TRUE
